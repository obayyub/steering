{
 "cells": [
  {
   "cell_type": "code",
   "source": "# Layer curves comparing shallow vs deep models (32B is the only deep model)\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\n\nfor j, concept in enumerate(CONCEPTS):\n    # Top row: raw layer curves\n    ax = axes[0, j]\n    for model in MODELS:\n        model_data = summaries_df[(summaries_df[\"concept\"] == concept) & (summaries_df[\"model\"] == model)]\n        style = '--' if LAYER_COUNTS[model] == 64 else '-'\n        linewidth = 2 if LAYER_COUNTS[model] == 64 else 1.5\n        ax.plot(model_data[\"layer\"], model_data[\"delta\"], style, \n                label=f\"{model} ({LAYER_COUNTS[model]}L)\", alpha=0.8, linewidth=linewidth)\n    ax.axhline(0, color='black', linestyle=':', alpha=0.3)\n    ax.set_title(f\"{concept.replace('_', ' ').title()}\")\n    ax.set_xlabel(\"Layer\")\n    ax.set_ylabel(\"Delta\")\n    ax.legend(fontsize=9)\n    \n    # Bottom row: normalized layer position\n    ax = axes[1, j]\n    for model in MODELS:\n        model_data = summaries_df[(summaries_df[\"concept\"] == concept) & (summaries_df[\"model\"] == model)]\n        normalized = model_data[\"layer\"] / LAYER_COUNTS[model]\n        style = '--' if LAYER_COUNTS[model] == 64 else '-'\n        linewidth = 2 if LAYER_COUNTS[model] == 64 else 1.5\n        ax.plot(normalized, model_data[\"delta\"], style, \n                label=f\"{model} ({LAYER_COUNTS[model]}L)\", alpha=0.8, linewidth=linewidth)\n    ax.axhline(0, color='black', linestyle=':', alpha=0.3)\n    ax.set_xlabel(\"Normalized Layer Position\")\n    ax.set_ylabel(\"Delta\")\n    ax.legend(fontsize=9)\n\nplt.suptitle(\"Solid = Shallow (36-40L), Dashed = Deep (64L, 32B only)\", fontsize=14, y=1.02)\nplt.tight_layout()\nplt.savefig(\"../results/logit_diff_sweep/layer_curves_depth_comparison.png\", dpi=150, bbox_inches=\"tight\")\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Best layer position as fraction of total layers\nprint(\"Best Layer Position (% of total layers):\")\nprint(\"=\"*70)\n\nposition_data = []\nfor model in MODELS:\n    row = {\"model\": model, \"layers\": LAYER_COUNTS[model]}\n    for concept in CONCEPTS:\n        model_best = best_layers[(best_layers[\"model\"] == model) & (best_layers[\"concept\"] == concept)]\n        if len(model_best) > 0:\n            layer = model_best[\"layer\"].values[0]\n            frac = layer / LAYER_COUNTS[model]\n            row[concept] = frac\n    position_data.append(row)\n\nposition_df = pd.DataFrame(position_data)\nposition_df = position_df.set_index(\"model\")\n\n# Display as percentages\ndisplay_df = position_df.copy()\nfor col in CONCEPTS:\n    display_df[col] = display_df[col].apply(lambda x: f\"{x:.0%}\" if pd.notna(x) else \"\")\nprint(display_df.to_string())\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"Pattern:\")\nprint(\"  4B, 8B, 14B: best layers in middle (50-65%)\")\nprint(\"  32B:         best layers LATE (69-80%) <-- OUTLIER\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Best Layer Position: 32B is an Outlier\n\n32B is unique - its best steering layers are in the final third (69-80%) for ALL concepts,\nwhile all other models (4B, 8B, 14B) have best layers in the middle (50-65%).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Correct architecture details from Qwen3 model configs\nLAYER_COUNTS = {\"4B\": 36, \"8B\": 36, \"14B\": 40, \"32B\": 64}\n\nprint(\"Model Architectures (from Qwen3 configs):\")\nprint(\"=\"*50)\nfor model in MODELS:\n    depth = \"DEEP\" if LAYER_COUNTS[model] == 64 else \"shallow\"\n    print(f\"  {model}: {LAYER_COUNTS[model]} layers ({depth})\")\n\n# Compare shallow vs deep (only 32B is deep)\nprint(\"\\n\" + \"=\"*50)\nprint(\"Average Best Delta: Shallow (36-40L) vs Deep (64L)\")\nprint(\"=\"*50)\n\nfor concept in CONCEPTS:\n    shallow_deltas = []\n    deep_deltas = []\n    \n    for model in MODELS:\n        model_best = best_layers[(best_layers[\"model\"] == model) & (best_layers[\"concept\"] == concept)]\n        if len(model_best) > 0:\n            delta = model_best[\"delta\"].values[0]\n            if LAYER_COUNTS[model] <= 40:\n                shallow_deltas.append(delta)\n            else:\n                deep_deltas.append(delta)\n    \n    shallow_avg = np.mean(shallow_deltas) if shallow_deltas else 0\n    deep_avg = np.mean(deep_deltas) if deep_deltas else 0\n    ratio = shallow_avg / deep_avg if deep_avg > 0 else 0\n    \n    print(f\"\\n{concept}:\")\n    print(f\"  Shallow (4B, 8B, 14B): {shallow_avg:.2f}\")\n    print(f\"  Deep (32B only):       {deep_avg:.2f}\")\n    print(f\"  Ratio:                 {ratio:.1f}x\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit Diff Layer Sweep Analysis\n",
    "\n",
    "Analyzing steering effects across 4B, 8B, 14B, 32B models for corrigible, self_awareness, and sycophancy concepts.\n",
    "\n",
    "**Methodology**: For each layer, we compute P(\"(A\" | prompt) vs P(\"(B\" | prompt) at the first generation position,\n",
    "measuring how steering shifts the model's latent disposition toward one answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"../results/logit_diff_sweep\")\n",
    "\n",
    "MODELS = [\"4B\", \"8B\", \"14B\", \"32B\"]\n",
    "CONCEPTS = [\"corrigible\", \"self_awareness\", \"sycophancy\"]\n",
    "\n",
    "# Load all per-sample data\n",
    "all_samples = []\n",
    "all_summaries = []\n",
    "\n",
    "for concept in CONCEPTS:\n",
    "    for model in MODELS:\n",
    "        model_dir = BASE_DIR / concept / f\"Qwen_Qwen3_{model}\"\n",
    "        \n",
    "        # Per-sample data\n",
    "        sample_path = model_dir / \"per_sample_all_layers.csv\"\n",
    "        if sample_path.exists():\n",
    "            df = pd.read_csv(sample_path)\n",
    "            all_samples.append(df)\n",
    "        \n",
    "        # Layer summary\n",
    "        summary_path = model_dir / \"layer_summary.csv\"\n",
    "        if summary_path.exists():\n",
    "            df = pd.read_csv(summary_path)\n",
    "            df[\"model\"] = model\n",
    "            df[\"concept\"] = concept\n",
    "            all_summaries.append(df)\n",
    "\n",
    "samples_df = pd.concat(all_samples, ignore_index=True)\n",
    "summaries_df = pd.concat(all_summaries, ignore_index=True)\n",
    "\n",
    "print(f\"Loaded {len(samples_df):,} per-sample rows\")\n",
    "print(f\"Loaded {len(summaries_df)} layer summaries\")\n",
    "print(f\"\\nModels: {samples_df['model'].unique()}\")\n",
    "print(f\"Concepts: {samples_df['concept'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best layer per model/concept\n",
    "best_layers = summaries_df.loc[summaries_df.groupby([\"model\", \"concept\"])[\"delta\"].idxmax()]\n",
    "best_layers = best_layers[[\"model\", \"concept\", \"layer\", \"delta\", \"baseline_mean\", \"positive_mean\", \"negative_mean\"]]\n",
    "best_layers = best_layers.sort_values([\"concept\", \"model\"])\n",
    "\n",
    "print(\"Best Layer per Model/Concept (by max delta):\")\n",
    "print(\"=\"*80)\n",
    "display(best_layers.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table of best deltas\n",
    "pivot = best_layers.pivot(index=\"model\", columns=\"concept\", values=\"delta\")\n",
    "pivot = pivot.reindex([\"4B\", \"8B\", \"14B\", \"32B\"])\n",
    "\n",
    "print(\"\\nBest Delta by Model/Concept:\")\n",
    "print(\"=\"*50)\n",
    "display(pivot.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer-wise Delta Curves\n",
    "\n",
    "How does steering effect (delta = positive - negative) vary across layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "for ax, concept in zip(axes, CONCEPTS):\n",
    "    concept_data = summaries_df[summaries_df[\"concept\"] == concept]\n",
    "    \n",
    "    for model in MODELS:\n",
    "        model_data = concept_data[concept_data[\"model\"] == model]\n",
    "        ax.plot(model_data[\"layer\"], model_data[\"delta\"], \n",
    "                marker=\"o\", markersize=3, label=model, alpha=0.8)\n",
    "    \n",
    "    ax.axhline(y=0, color=\"black\", linestyle=\"--\", alpha=0.3)\n",
    "    ax.set_xlabel(\"Layer\")\n",
    "    ax.set_title(concept.replace(\"_\", \" \").title())\n",
    "    ax.legend(title=\"Model\")\n",
    "\n",
    "axes[0].set_ylabel(\"Delta (logit diff: +1.0 steering - (-1.0 steering))\")\n",
    "plt.suptitle(\"Steering Effect (Delta) by Layer\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/logit_diff_sweep/layer_delta_curves.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Layer Curves\n",
    "\n",
    "Normalize layer index to [0, 1] to compare across model sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Add normalized layer position (correct layer counts from Qwen3 configs)\nlayer_counts = {\"4B\": 36, \"8B\": 36, \"14B\": 40, \"32B\": 64}\n\nsummaries_df[\"layer_frac\"] = summaries_df.apply(\n    lambda row: row[\"layer\"] / layer_counts[row[\"model\"]], axis=1\n)\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n\nfor ax, concept in zip(axes, CONCEPTS):\n    concept_data = summaries_df[summaries_df[\"concept\"] == concept]\n    \n    for model in MODELS:\n        model_data = concept_data[concept_data[\"model\"] == model]\n        ax.plot(model_data[\"layer_frac\"], model_data[\"delta\"], \n                marker=\"o\", markersize=3, label=model, alpha=0.8)\n    \n    ax.axhline(y=0, color=\"black\", linestyle=\"--\", alpha=0.3)\n    ax.set_xlabel(\"Normalized Layer Position\")\n    ax.set_title(concept.replace(\"_\", \" \").title())\n    ax.legend(title=\"Model\")\n\naxes[0].set_ylabel(\"Delta\")\nplt.suptitle(\"Steering Effect by Normalized Layer Position\", fontsize=14, y=1.02)\nplt.tight_layout()\nplt.savefig(\"../results/logit_diff_sweep/layer_delta_curves_normalized.png\", dpi=150, bbox_inches=\"tight\")\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Logit Diffs at Best Layers\n",
    "\n",
    "Violin plots showing per-sample logit diff distributions at the best layer for each model/concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best layer for each model/concept\n",
    "best_layer_map = best_layers.set_index([\"model\", \"concept\"])[\"layer\"].to_dict()\n",
    "\n",
    "# Filter samples to best layers only\n",
    "samples_df[\"is_best_layer\"] = samples_df.apply(\n",
    "    lambda row: row[\"layer\"] == best_layer_map.get((row[\"model\"], row[\"concept\"]), -1),\n",
    "    axis=1\n",
    ")\n",
    "best_samples = samples_df[samples_df[\"is_best_layer\"]].copy()\n",
    "\n",
    "print(f\"Samples at best layers: {len(best_samples):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for ax, concept in zip(axes, CONCEPTS):\n",
    "    data = best_samples[best_samples[\"concept\"] == concept]\n",
    "    \n",
    "    # Order models\n",
    "    data[\"model\"] = pd.Categorical(data[\"model\"], categories=MODELS, ordered=True)\n",
    "    \n",
    "    sns.violinplot(\n",
    "        data=data, x=\"model\", y=\"logit_diff_matching\", hue=\"strength\",\n",
    "        ax=ax, palette=\"coolwarm\", inner=\"quartile\", cut=0\n",
    "    )\n",
    "    \n",
    "    ax.axhline(y=0, color=\"black\", linestyle=\"--\", alpha=0.3)\n",
    "    ax.set_xlabel(\"Model\")\n",
    "    ax.set_title(f\"{concept.replace('_', ' ').title()}\\n(best layer per model)\")\n",
    "    ax.legend(title=\"Strength\", loc=\"upper right\")\n",
    "\n",
    "axes[0].set_ylabel(\"Logit Diff (matching direction)\")\n",
    "plt.suptitle(\"Logit Diff Distributions at Best Layers\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/logit_diff_sweep/best_layer_violins.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps: Mean Logit Diff by Strength and Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(model, concept):\n",
    "    data = samples_df[(samples_df[\"model\"] == model) & (samples_df[\"concept\"] == concept)]\n",
    "    \n",
    "    pivot = data.pivot_table(\n",
    "        index=\"layer\", columns=\"strength\", values=\"logit_diff_matching\", aggfunc=\"mean\"\n",
    "    )\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 8))\n",
    "    sns.heatmap(pivot, cmap=\"RdBu_r\", center=0, ax=ax, cbar_kws={\"label\": \"Mean Logit Diff\"})\n",
    "    ax.set_title(f\"{model} - {concept.replace('_', ' ').title()}\")\n",
    "    ax.set_ylabel(\"Layer\")\n",
    "    ax.set_xlabel(\"Steering Strength\")\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Show one example\n",
    "fig = plot_heatmap(\"14B\", \"corrigible\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All heatmaps in a grid\n",
    "fig, axes = plt.subplots(len(MODELS), len(CONCEPTS), figsize=(14, 18))\n",
    "\n",
    "for i, model in enumerate(MODELS):\n",
    "    for j, concept in enumerate(CONCEPTS):\n",
    "        ax = axes[i, j]\n",
    "        data = samples_df[(samples_df[\"model\"] == model) & (samples_df[\"concept\"] == concept)]\n",
    "        \n",
    "        pivot = data.pivot_table(\n",
    "            index=\"layer\", columns=\"strength\", values=\"logit_diff_matching\", aggfunc=\"mean\"\n",
    "        )\n",
    "        \n",
    "        sns.heatmap(pivot, cmap=\"RdBu_r\", center=0, ax=ax, \n",
    "                    cbar=j == len(CONCEPTS) - 1,\n",
    "                    cbar_kws={\"label\": \"Mean Logit Diff\"} if j == len(CONCEPTS) - 1 else {})\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.set_title(concept.replace(\"_\", \" \").title())\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f\"{model}\\nLayer\")\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "        if i == len(MODELS) - 1:\n",
    "            ax.set_xlabel(\"Strength\")\n",
    "        else:\n",
    "            ax.set_xlabel(\"\")\n",
    "\n",
    "plt.suptitle(\"Mean Logit Diff by Layer and Steering Strength\", fontsize=14, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/logit_diff_sweep/heatmap_grid.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Baseline (strength=0) Distributions\n",
    "\n",
    "What's the model's natural disposition without steering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_samples = best_samples[best_samples[\"strength\"] == 0.0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for ax, concept in zip(axes, CONCEPTS):\n",
    "    data = baseline_samples[baseline_samples[\"concept\"] == concept]\n",
    "    data[\"model\"] = pd.Categorical(data[\"model\"], categories=MODELS, ordered=True)\n",
    "    \n",
    "    sns.boxplot(data=data, x=\"model\", y=\"logit_diff_matching\", ax=ax, palette=\"Set2\")\n",
    "    \n",
    "    ax.axhline(y=0, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"No preference\")\n",
    "    ax.set_xlabel(\"Model\")\n",
    "    ax.set_title(concept.replace(\"_\", \" \").title())\n",
    "\n",
    "axes[0].set_ylabel(\"Baseline Logit Diff (strength=0)\")\n",
    "plt.suptitle(\"Model's Natural Disposition (No Steering)\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/logit_diff_sweep/baseline_distributions.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect Size: Positive vs Negative Steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare steered distributions\n",
    "fig, axes = plt.subplots(len(MODELS), len(CONCEPTS), figsize=(14, 12))\n",
    "\n",
    "for i, model in enumerate(MODELS):\n",
    "    for j, concept in enumerate(CONCEPTS):\n",
    "        ax = axes[i, j]\n",
    "        data = best_samples[(best_samples[\"model\"] == model) & (best_samples[\"concept\"] == concept)]\n",
    "        \n",
    "        for strength, color in [(-1.0, \"blue\"), (0.0, \"gray\"), (1.0, \"red\")]:\n",
    "            subset = data[data[\"strength\"] == strength][\"logit_diff_matching\"]\n",
    "            ax.hist(subset, bins=30, alpha=0.5, label=f\"{strength:+.1f}\", color=color, density=True)\n",
    "        \n",
    "        ax.axvline(x=0, color=\"black\", linestyle=\"--\", alpha=0.3)\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.set_title(concept.replace(\"_\", \" \").title())\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f\"{model}\")\n",
    "        if i == len(MODELS) - 1:\n",
    "            ax.set_xlabel(\"Logit Diff\")\n",
    "        if i == 0 and j == len(CONCEPTS) - 1:\n",
    "            ax.legend(title=\"Strength\")\n",
    "\n",
    "plt.suptitle(\"Logit Diff Distributions by Steering Strength (Best Layers)\", fontsize=14, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/logit_diff_sweep/strength_histograms.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary stats for best layers\n",
    "summary_stats = best_samples.groupby([\"model\", \"concept\", \"strength\"]).agg({\n",
    "    \"logit_diff_matching\": [\"mean\", \"std\", \"median\"]\n",
    "}).round(3)\n",
    "\n",
    "summary_stats.columns = [\"mean\", \"std\", \"median\"]\n",
    "summary_stats = summary_stats.reset_index()\n",
    "\n",
    "print(\"Summary Statistics at Best Layers:\")\n",
    "display(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect size (Cohen's d approximation): (mean_pos - mean_neg) / pooled_std\n",
    "effect_sizes = []\n",
    "\n",
    "for model in MODELS:\n",
    "    for concept in CONCEPTS:\n",
    "        data = best_samples[(best_samples[\"model\"] == model) & (best_samples[\"concept\"] == concept)]\n",
    "        \n",
    "        pos = data[data[\"strength\"] == 1.0][\"logit_diff_matching\"]\n",
    "        neg = data[data[\"strength\"] == -1.0][\"logit_diff_matching\"]\n",
    "        \n",
    "        mean_diff = pos.mean() - neg.mean()\n",
    "        pooled_std = np.sqrt((pos.std()**2 + neg.std()**2) / 2)\n",
    "        cohens_d = mean_diff / pooled_std if pooled_std > 0 else 0\n",
    "        \n",
    "        effect_sizes.append({\n",
    "            \"model\": model,\n",
    "            \"concept\": concept,\n",
    "            \"mean_positive\": pos.mean(),\n",
    "            \"mean_negative\": neg.mean(),\n",
    "            \"delta\": mean_diff,\n",
    "            \"cohens_d\": cohens_d,\n",
    "        })\n",
    "\n",
    "effect_df = pd.DataFrame(effect_sizes)\n",
    "print(\"\\nEffect Sizes (Cohen's d):\")\n",
    "display(effect_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect size heatmap\n",
    "pivot = effect_df.pivot(index=\"model\", columns=\"concept\", values=\"cohens_d\")\n",
    "pivot = pivot.reindex([\"4B\", \"8B\", \"14B\", \"32B\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.heatmap(pivot, annot=True, fmt=\".2f\", cmap=\"RdYlGn\", center=0, ax=ax,\n",
    "            cbar_kws={\"label\": \"Cohen's d\"})\n",
    "ax.set_title(\"Steering Effect Size (Cohen's d) at Best Layers\")\n",
    "ax.set_ylabel(\"Model\")\n",
    "ax.set_xlabel(\"Concept\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/logit_diff_sweep/effect_size_heatmap.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. Best Layers by Model/Concept:\")\n",
    "for _, row in best_layers.iterrows():\n",
    "    print(f\"   {row['model']:4s} {row['concept']:15s}: layer {int(row['layer']):2d}, delta={row['delta']:+.2f}\")\n",
    "\n",
    "print(\"\\n2. Effect Sizes (Cohen's d):\")\n",
    "for _, row in effect_df.iterrows():\n",
    "    strength = \"strong\" if abs(row['cohens_d']) > 0.8 else \"medium\" if abs(row['cohens_d']) > 0.5 else \"weak\"\n",
    "    print(f\"   {row['model']:4s} {row['concept']:15s}: d={row['cohens_d']:+.2f} ({strength})\")\n",
    "\n",
    "print(\"\\n3. Strongest Steering Concepts:\")\n",
    "concept_avg = effect_df.groupby(\"concept\")[\"cohens_d\"].mean().sort_values(ascending=False)\n",
    "for concept, d in concept_avg.items():\n",
    "    print(f\"   {concept}: avg d = {d:+.2f}\")\n",
    "\n",
    "print(\"\\n4. Model Size Scaling:\")\n",
    "model_avg = effect_df.groupby(\"model\")[\"cohens_d\"].mean()\n",
    "model_avg = model_avg.reindex([\"4B\", \"8B\", \"14B\", \"32B\"])\n",
    "for model, d in model_avg.items():\n",
    "    print(f\"   {model}: avg d = {d:+.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary to JSON\n",
    "summary = {\n",
    "    \"best_layers\": best_layers.to_dict(orient=\"records\"),\n",
    "    \"effect_sizes\": effect_df.to_dict(orient=\"records\"),\n",
    "    \"concept_avg_effect\": concept_avg.to_dict(),\n",
    "    \"model_avg_effect\": model_avg.to_dict(),\n",
    "}\n",
    "\n",
    "with open(\"../results/logit_diff_sweep/analysis_summary.json\", \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved analysis_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Architecture Depth Analysis\n\n**Key Finding**: 32B is the only deep model and the hardest to steer.\n\n| Model | Layers | Hidden Dim |\n|-------|--------|------------|\n| 4B | 36 | 2560 |\n| 8B | 36 | 4096 |\n| 14B | 40 | 5120 |\n| 32B | 64 | 5120 |\n\n32B (64 layers) is significantly harder to steer than the shallower models (36-40 layers).",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}